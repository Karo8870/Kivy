{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T05:12:56.790546Z",
     "start_time": "2025-05-08T05:12:37.352102Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from embeddings.autoencoder_embeddings.recipe_autoencoder import RecipeAutoencoder\n",
    "\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data,\n",
    "            tokenizer,\n",
    "            tag_vocab,\n",
    "            category_vocab,\n",
    "            ingredient_vocab,\n",
    "            max_length=128,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "        self.ingredient_vocab = ingredient_vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def encode_strings(self, strings, vocab):\n",
    "        \"\"\"Convert a list of strings to indices based on the provided vocabulary.\"\"\"\n",
    "        return [\n",
    "            vocab.get(s, 0) for s in strings\n",
    "        ]  # Map to index, default to 0 if not found\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recipe = self.data[idx]\n",
    "\n",
    "        # Tokenize name, description, and steps\n",
    "        name = self.tokenizer(\n",
    "            recipe[\"name\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        description = self.tokenizer(\n",
    "            recipe[\"description\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        steps = [\n",
    "            self.tokenizer(\n",
    "                step,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for step in recipe[\"steps\"]\n",
    "        ]\n",
    "\n",
    "        # Encode tags and ingredients as indices\n",
    "        tags = torch.tensor(\n",
    "            self.encode_strings(recipe[\"tags\"], self.tag_vocab), dtype=torch.long\n",
    "        )\n",
    "        ingredients = torch.tensor(\n",
    "            self.encode_strings(recipe[\"ingredients\"], self.ingredient_vocab),\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "        # Encode category as a single index\n",
    "        category = torch.tensor(\n",
    "            self.category_vocab.get(recipe[\"category\"], 0), dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Nutriments as a tensor\n",
    "        nutriments = torch.tensor(recipe[\"nutriments\"], dtype=torch.float32)\n",
    "\n",
    "        return name, description, steps, tags, category, ingredients, nutriments\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def build_vocab(items, min_freq=1):\n",
    "    \"\"\"\n",
    "    Build a vocabulary from a list of strings or list of lists of strings.\n",
    "    Args:\n",
    "        items (list): The input data (e.g., tags, categories, ingredients).\n",
    "        min_freq (int): Minimum frequency for a string to be included in the vocab.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each string to a unique index.\n",
    "    \"\"\"\n",
    "    if isinstance(items[0], list):  # Handle lists of lists (e.g., tags or ingredients)\n",
    "        items = [item for sublist in items for item in sublist]\n",
    "    counter = Counter(items)\n",
    "    vocab = {\n",
    "        word: idx + 1\n",
    "        for idx, (word, count) in enumerate(counter.items())\n",
    "        if count >= min_freq\n",
    "    }  # Start indices from 1\n",
    "    vocab[\"<UNK>\"] = 0  # Add a token for unknown strings\n",
    "    return vocab\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def train_minilm_autoencoder(\n",
    "        train_data,\n",
    "        val_data,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        max_length=128,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "):\n",
    "    # Step 1: Build vocabularies\n",
    "    tag_vocab = build_vocab([recipe[\"tags\"] for recipe in train_data], min_freq=1)\n",
    "    category_vocab = build_vocab(\n",
    "        [recipe[\"category\"] for recipe in train_data], min_freq=1\n",
    "    )\n",
    "    ingredient_vocab = build_vocab(\n",
    "        [recipe[\"ingredients\"] for recipe in train_data], min_freq=1\n",
    "    )\n",
    "\n",
    "    # Step 2: Initialize tokenizer, dataset, and dataloaders\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")\n",
    "    train_dataset = RecipeDataset(\n",
    "        train_data,\n",
    "        tokenizer,\n",
    "        tag_vocab,\n",
    "        category_vocab,\n",
    "        ingredient_vocab,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    val_dataset = RecipeDataset(\n",
    "        val_data,\n",
    "        tokenizer,\n",
    "        tag_vocab,\n",
    "        category_vocab,\n",
    "        ingredient_vocab,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Step 3: Initialize the model, loss functions, and optimizer\n",
    "    model = RecipeAutoencoder(\n",
    "        latent_dim=256, ingredient_vocab_size=len(ingredient_vocab)\n",
    "    ).to(device)\n",
    "    criterion_text = nn.MSELoss()\n",
    "    criterion_tags = nn.BCEWithLogitsLoss()\n",
    "    criterion_category = nn.CrossEntropyLoss()\n",
    "    criterion_ingredients = nn.BCEWithLogitsLoss()\n",
    "    criterion_nutriments = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": model.text_encoder.transformer.parameters(),\n",
    "                \"lr\": 1e-5,\n",
    "            },  # Fine-tune MiniLM\n",
    "            {\"params\": model.parameters(), \"lr\": 1e-4},  # Other parts of the model\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Step 4: Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to the training device\n",
    "            name, description, steps, tags, category, ingredients, nutriments = batch\n",
    "            name = {key: val.to(device) for key, val in name.items()}\n",
    "            description = {key: val.to(device) for key, val in description.items()}\n",
    "            steps = [\n",
    "                {key: val.to(device) for key, val in step.items()} for step in steps\n",
    "            ]\n",
    "            tags, category, ingredients, nutriments = (\n",
    "                tags.to(device),\n",
    "                category.to(device),\n",
    "                ingredients.to(device),\n",
    "                nutriments.to(device),\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            (\n",
    "                latent_embedding,\n",
    "                text_decoded,\n",
    "                tags_decoded,\n",
    "                category_decoded,\n",
    "                ingredients_decoded,\n",
    "                nutriments_decoded,\n",
    "            ) = model(name, description, steps, tags, category, ingredients, nutriments)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_text = criterion_text(text_decoded, name[\"input_ids\"].float())\n",
    "            loss_tags = criterion_tags(\n",
    "                tags_decoded,\n",
    "                nn.functional.one_hot(tags, num_classes=len(tag_vocab)).float(),\n",
    "            )\n",
    "            loss_category = criterion_category(category_decoded, category)\n",
    "            loss_ingredients = criterion_ingredients(\n",
    "                ingredients_decoded,\n",
    "                nn.functional.one_hot(\n",
    "                    ingredients, num_classes=len(ingredient_vocab)\n",
    "                ).float(),\n",
    "            )\n",
    "            loss_nutriments = criterion_nutriments(nutriments_decoded, nutriments)\n",
    "\n",
    "            # Combine losses\n",
    "            loss = (\n",
    "                    loss_text\n",
    "                    + loss_tags\n",
    "                    + loss_category\n",
    "                    + loss_ingredients\n",
    "                    + loss_nutriments\n",
    "            )\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Step 5: Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                name, description, steps, tags, category, ingredients, nutriments = (\n",
    "                    batch\n",
    "                )\n",
    "                name = {key: val.to(device) for key, val in name.items()}\n",
    "                description = {key: val.to(device) for key, val in description.items()}\n",
    "                steps = [\n",
    "                    {key: val.to(device) for key, val in step.items()} for step in steps\n",
    "                ]\n",
    "                tags, category, ingredients, nutriments = (\n",
    "                    tags.to(device),\n",
    "                    category.to(device),\n",
    "                    ingredients.to(device),\n",
    "                    nutriments.to(device),\n",
    "                )\n",
    "\n",
    "                (\n",
    "                    latent_embedding,\n",
    "                    text_decoded,\n",
    "                    tags_decoded,\n",
    "                    category_decoded,\n",
    "                    ingredients_decoded,\n",
    "                    nutriments_decoded,\n",
    "                ) = model(\n",
    "                    name, description, steps, tags, category, ingredients, nutriments\n",
    "                )\n",
    "\n",
    "                loss_text = criterion_text(text_decoded, name[\"input_ids\"].float())\n",
    "                loss_tags = criterion_tags(\n",
    "                    tags_decoded,\n",
    "                    nn.functional.one_hot(tags, num_classes=len(tag_vocab)).float(),\n",
    "                )\n",
    "                loss_category = criterion_category(category_decoded, category)\n",
    "                loss_ingredients = criterion_ingredients(\n",
    "                    ingredients_decoded,\n",
    "                    nn.functional.one_hot(\n",
    "                        ingredients, num_classes=len(ingredient_vocab)\n",
    "                    ).float(),\n",
    "                )\n",
    "                loss_nutriments = criterion_nutriments(nutriments_decoded, nutriments)\n",
    "\n",
    "                loss = (\n",
    "                        loss_text\n",
    "                        + loss_tags\n",
    "                        + loss_category\n",
    "                        + loss_ingredients\n",
    "                        + loss_nutriments\n",
    "                )\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{epochs}] - Train Loss: {total_train_loss:.4f}, Val Loss: {total_val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), \"minilm_recipe_autoencoder.pth\")\n",
    "    print(\"Model training complete and saved as 'minilm_recipe_autoencoder.pth'.\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_pickle('embeddings_train_data.pkl')\n",
    "\n",
    "# Split the DataFrame into training and validation datasets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert DataFrame rows into a list of dictionaries\n",
    "train_data = train_df.to_dict(orient=\"records\")\n",
    "val_data = val_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Call the training function\n",
    "train_minilm_autoencoder(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    max_length=128,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karo/Developer/Kivy/research/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/karo/Developer/Kivy/research/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 306\u001B[0m\n\u001B[1;32m    303\u001B[0m val_data \u001B[38;5;241m=\u001B[39m val_df\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# Call the training function\u001B[39;00m\n\u001B[0;32m--> 306\u001B[0m \u001B[43mtrain_minilm_autoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    313\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 151\u001B[0m, in \u001B[0;36mtrain_minilm_autoencoder\u001B[0;34m(train_data, val_data, epochs, batch_size, max_length, device)\u001B[0m\n\u001B[1;32m    148\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    150\u001B[0m \u001B[38;5;66;03m# Step 3: Initialize the model, loss functions, and optimizer\u001B[39;00m\n\u001B[0;32m--> 151\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mRecipeAutoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mingredient_vocab_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mingredient_vocab\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    154\u001B[0m criterion_text \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m    155\u001B[0m criterion_tags \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss()\n",
      "File \u001B[0;32m~/Developer/Kivy/research/embeddings/autoencoder_embeddings/recipe_autoencoder.py:15\u001B[0m, in \u001B[0;36mRecipeAutoencoder.__init__\u001B[0;34m(self, latent_dim, ingredient_vocab_size)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28msuper\u001B[39m(RecipeAutoencoder, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Submodules\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_encoder \u001B[38;5;241m=\u001B[39m \u001B[43mTextEncoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransformer_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicrosoft/MiniLM-L12-H384-uncased\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext_embedding_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategorical_encoder \u001B[38;5;241m=\u001B[39m CategoricalEncoder(\n\u001B[1;32m     20\u001B[0m     num_tags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m305\u001B[39m, num_categories\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, embedding_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m\n\u001B[1;32m     21\u001B[0m )\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mingredient_encoder \u001B[38;5;241m=\u001B[39m IngredientEncoder(\n\u001B[1;32m     23\u001B[0m     ingredient_vocab_size\u001B[38;5;241m=\u001B[39mingredient_vocab_size, embedding_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m\n\u001B[1;32m     24\u001B[0m )\n",
      "File \u001B[0;32m~/Developer/Kivy/research/embeddings/autoencoder_embeddings/text_encoder.py:12\u001B[0m, in \u001B[0;36mTextEncoder.__init__\u001B[0;34m(self, transformer_model, text_embedding_dim)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m      8\u001B[0m     transformer_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicrosoft/MiniLM-L12-H384-uncased\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m     text_embedding_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,\n\u001B[1;32m     10\u001B[0m ):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28msuper\u001B[39m(TextEncoder, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformer_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_text \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;241m384\u001B[39m, text_embedding_dim\n\u001B[1;32m     15\u001B[0m     )\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:571\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mconfig_class \u001B[38;5;241m==\u001B[39m config\u001B[38;5;241m.\u001B[39msub_configs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_config\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    570\u001B[0m         config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget_text_config()\n\u001B[0;32m--> 571\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    577\u001B[0m )\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:279\u001B[0m, in \u001B[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m old_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mget_default_dtype()\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_default_dtype(old_dtype)\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:4260\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   4250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   4251\u001B[0m     gguf_file\n\u001B[1;32m   4252\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4253\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisk\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisk\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[1;32m   4254\u001B[0m ):\n\u001B[1;32m   4255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   4256\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4257\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloaded from GGUF files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4258\u001B[0m     )\n\u001B[0;32m-> 4260\u001B[0m checkpoint_files, sharded_metadata \u001B[38;5;241m=\u001B[39m \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4262\u001B[0m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4267\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4273\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4276\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4278\u001B[0m is_sharded \u001B[38;5;241m=\u001B[39m sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4279\u001B[0m is_quantized \u001B[38;5;241m=\u001B[39m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:1026\u001B[0m, in \u001B[0;36m_get_resolved_checkpoint_files\u001B[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001B[0m\n\u001B[1;32m   1023\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1024\u001B[0m         \u001B[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001B[39;00m\n\u001B[1;32m   1025\u001B[0m         filename \u001B[38;5;241m=\u001B[39m _add_variant(WEIGHTS_NAME, variant)\n\u001B[0;32m-> 1026\u001B[0m         resolved_archive_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcached_file_kwargs\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;241m==\u001B[39m _add_variant(WEIGHTS_NAME, variant):\n\u001B[1;32m   1030\u001B[0m     \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n\u001B[1;32m   1031\u001B[0m     resolved_archive_file \u001B[38;5;241m=\u001B[39m cached_file(\n\u001B[1;32m   1032\u001B[0m         pretrained_model_name_or_path,\n\u001B[1;32m   1033\u001B[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001B[1;32m   1034\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcached_file_kwargs,\n\u001B[1;32m   1035\u001B[0m     )\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:266\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcached_file\u001B[39m(\n\u001B[1;32m    209\u001B[0m     path_or_repo_id: Union[\u001B[38;5;28mstr\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike],\n\u001B[1;32m    210\u001B[0m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    212\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    213\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m     file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m     file \u001B[38;5;241m=\u001B[39m file[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m file\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:424\u001B[0m, in \u001B[0;36mcached_files\u001B[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    422\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    423\u001B[0m         \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[0;32m--> 424\u001B[0m         \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    439\u001B[0m         snapshot_download(\n\u001B[1;32m    440\u001B[0m             path_or_repo_id,\n\u001B[1;32m    441\u001B[0m             allow_patterns\u001B[38;5;241m=\u001B[39mfull_filenames,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    450\u001B[0m             local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    451\u001B[0m         )\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:961\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[0m\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[1;32m    942\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[1;32m    943\u001B[0m         local_dir\u001B[38;5;241m=\u001B[39mlocal_dir,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    958\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    959\u001B[0m     )\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 961\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[1;32m    963\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[1;32m    965\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[1;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[1;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1112\u001B[0m, in \u001B[0;36m_hf_hub_download_to_cache_dir\u001B[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[0m\n\u001B[1;32m   1110\u001B[0m Path(lock_path)\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[0;32m-> 1112\u001B[0m     \u001B[43m_download_to_tmp_and_move\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.incomplete\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43metag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1124\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(pointer_path):\n\u001B[1;32m   1125\u001B[0m         _create_symlink(blob_path, pointer_path, new_blob\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1675\u001B[0m, in \u001B[0;36m_download_to_tmp_and_move\u001B[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[0m\n\u001B[1;32m   1669\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1670\u001B[0m             logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m   1671\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXet Storage is enabled for this repo, but the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhf_xet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m package is not installed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1672\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFalling back to regular HTTP download. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1673\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1674\u001B[0m             )\n\u001B[0;32m-> 1675\u001B[0m         \u001B[43mhttp_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1676\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1678\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1679\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1680\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1681\u001B[0m \u001B[43m            \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1682\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1684\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownload complete. Moving file to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdestination_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1685\u001B[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:449\u001B[0m, in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001B[0m\n\u001B[1;32m    447\u001B[0m new_resume_size \u001B[38;5;241m=\u001B[39m resume_size\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39mconstants\u001B[38;5;241m.\u001B[39mDOWNLOAD_CHUNK_SIZE):\n\u001B[1;32m    450\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk:  \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[1;32m    451\u001B[0m             progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(chunk))\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/requests/models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/urllib3/response.py:1066\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1064\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1065\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1066\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1068\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m   1069\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/urllib3/response.py:955\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    952\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[1;32m    953\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[0;32m--> 955\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    957\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[1;32m    959\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/urllib3/response.py:879\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    876\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    878\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 879\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    887\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    888\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    889\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Developer/Kivy/research/.venv/lib/python3.9/site-packages/urllib3/response.py:862\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1()\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:459\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    458\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 459\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:503\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    498\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    500\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 503\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    505\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
